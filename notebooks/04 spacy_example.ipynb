{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using lemma with spaCy\n",
    "This is an example of how to use lemma with spaCy. \n",
    "\n",
    "**Caution**: The Danish model included with spaCy is not trained for POS tagging. This model can not be used with Lemmy since the Lemmy pipeline component for spaCy requires POS tags. You must train your own spaCy model capable of POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import da_custom_model as da # name of your spaCy model\n",
    "import logging\n",
    "import regex\n",
    "import lemmy.pipe\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our Danish spaCy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = da.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an instance of the lemma pipeline component and add it to the spaCy pipeline. We make sure to add it *after* the POS tagger in order for the lemmatizer to have access to the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = lemmy.pipe.load()\n",
    "nlp.add_pipe(pipe, after='tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to it. Now we can access the lemmas of each token using the `._.lemmas` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akvarie']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"akvariernes\")[0]._.lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_example(text):\n",
    "    row_format = \"{token:12}| {pos:12}| {lemma:12}\"\n",
    "    print(row_format.format(token=\"TOKEN\", pos=\"POS\", lemma=\"LEMMA\"))\n",
    "    print(\"-\"*36)\n",
    "    rows = [(t.orth_, t.pos_, \" / \".join(t._.lemmas)) for t in nlp(text)]\n",
    "    for token, pos, lemma in rows:\n",
    "        print(row_format.format(token=token, pos=pos, lemma=lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN       | POS         | LEMMA       \n",
      "------------------------------------\n",
      "Han         | PRON        | -PRON-      \n",
      "er          | AUX         | være        \n",
      "jordemoder  | NOUN        | jordemor    \n",
      "og          | CCONJ       | og          \n",
      "hun         | PRON        | -PRON-      \n",
      "går         | VERB        | gå          \n",
      "på          | ADP         | på          \n",
      "gymnasium   | NOUN        | gymnasie    \n",
      ".           | PUNCT       | .           \n"
     ]
    }
   ],
   "source": [
    "_print_example(\"Han er jordemoder og hun går på gymnasium.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
