{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using lemma with spaCy\n",
    "This is an example of how to use lemma with spaCy. \n",
    "\n",
    "**Caution**: The Danish model included with spaCy is not trained for POS tagging. This model can not be used with lemma since the lemma pipeline component for spaCy requires POS tags. You must train your own spaCy model capable of POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import da_custom_model as da # Name of your spaCy model\n",
    "import logging\n",
    "import regex\n",
    "import lemma\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our Danish spaCy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = da.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an instance of the lemma pipeline component and add it to the spaCy pipeline. We make sure to add it *after* the POS tagger in order for the lemmatizer to have access to the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "component = lemma.load_pipeline_component()\n",
    "nlp.add_pipe(component, after='tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to it. Now we can access the lemma of each token using the `._.lemma` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'akvarie'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"akvariernes\")[0]._.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_example(text):\n",
    "    row_format = \"{token:12}| {pos:12}| {lemma:12}\"\n",
    "    print(row_format.format(token=\"TOKEN\", pos=\"POS\", lemma=\"LEMMA\"))\n",
    "    print(\"-\"*36)\n",
    "    rows = [(t.orth_, t.pos_, t._.lemma if t._.lemma else \"None\") for t in nlp(text)]\n",
    "    for token, pos, lemma in rows:\n",
    "        print(row_format.format(token=token, pos=pos, lemma=lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN       | POS         | LEMMA       \n",
      "------------------------------------\n",
      "Han         | PRON        | -PRON-      \n",
      "er          | AUX         | være        \n",
      "jordemoder  | NOUN        | jordemor    \n",
      "og          | CCONJ       | og          \n",
      "hun         | PRON        | -PRON-      \n",
      "går         | VERB        | gå          \n",
      "på          | ADP         | på          \n",
      "gymnasium   | NOUN        | gymnasie    \n",
      ".           | PUNCT       | .           \n"
     ]
    }
   ],
   "source": [
    "_print_example(\"Han er jordemoder og hun går på gymnasium.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
